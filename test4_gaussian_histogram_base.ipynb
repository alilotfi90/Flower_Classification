{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alilotfi90/Flower_Classification/blob/main/test4_gaussian_histogram_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D36XtCP2P_QD",
        "outputId": "b2013507-0f34-47b1-8a3d-5f9743573bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from zipfile import ZipFile\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Oo3DrC8bW-4K"
      },
      "outputs": [],
      "source": [
        "\n",
        "import zipfile\n",
        "\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/flowerimages.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('unzipped_images_flower')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUR74fwDQNu_",
        "outputId": "e847e60d-dbe4-433a-bdfa-9555f60ac1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-3f11d0df2342>:33: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  image = image.resize(target_size, Image.ANTIALIAS)\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "unzipped_folder = '/content/unzipped_images_flower/flowers'\n",
        "output_folder = '/content/resized_images_flower'\n",
        "\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "subdirectories = [d for d in os.listdir(unzipped_folder) if os.path.isdir(os.path.join(unzipped_folder, d))]\n",
        "\n",
        "# seen = set()\n",
        "for flower_category in subdirectories:\n",
        "    input_folder = os.path.join(unzipped_folder, flower_category)\n",
        "    output_category_folder = os.path.join(output_folder, flower_category)\n",
        "\n",
        "\n",
        "    os.makedirs(output_category_folder, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(input_folder) if f.endswith('.jpg')]\n",
        "\n",
        "    for image_file in image_files:\n",
        "      input_image_path = os.path.join(input_folder, image_file)\n",
        "      output_image_path = os.path.join(output_category_folder, image_file)\n",
        "\n",
        "      image = Image.open(input_image_path)\n",
        "\n",
        "      # Ensure the image is RGB\n",
        "      image = image.convert(\"RGB\")\n",
        "\n",
        "      # Resize the image\n",
        "      target_size = (224, 224)\n",
        "      image = image.resize(target_size, Image.ANTIALIAS)\n",
        "\n",
        "      image.save(output_image_path)\n",
        "\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "max_images_per_class =60\n",
        "data = []\n",
        "\n",
        "for flower_category in subdirectories:\n",
        "    category_folder = os.path.join(output_folder, flower_category)\n",
        "    image_files = [f for f in os.listdir(category_folder) if f.endswith('.jpg')]\n",
        "    label = subdirectories.index(flower_category)  # label = folder's name\n",
        "\n",
        "    # Limit the number of images to max_images_per_class\n",
        "    image_files = image_files[:max_images_per_class]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(category_folder, image_file)\n",
        "        data.append((image_path, label))\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from PIL import ImageEnhance\n",
        "\n",
        "# class HistEqualize(object):\n",
        "#     def __call__(self, img):\n",
        "#         if img.mode != 'L':\n",
        "#             img = img.convert('L')\n",
        "#         return Image.fromarray(cv2.equalizeHist(np.array(img)))\n",
        "\n",
        "#     def __repr__(self):\n",
        "#         return self.__class__.__name__ + '()'\n",
        "\n",
        "# hist_equalize_transform = transforms.Compose([\n",
        "#     HistEqualize(),\n",
        "# ])\n",
        "\n",
        "# # Display original and transformed images side-by-side\n",
        "# num_images_to_display = 5\n",
        "# chosen_indices = np.random.choice(len(data), num_images_to_display, replace=False)\n",
        "\n",
        "# fig, axs = plt.subplots(num_images_to_display, 2, figsize=(10, 4*num_images_to_display))\n",
        "\n",
        "# for i, idx in enumerate(chosen_indices):\n",
        "#     img_path, _ = data[idx]\n",
        "#     original_img = Image.open(img_path)\n",
        "#     transformed_img = hist_equalize_transform(original_img)\n",
        "\n",
        "#     axs[i, 0].imshow(original_img)\n",
        "#     axs[i, 0].set_title(\"Original Image\")\n",
        "#     axs[i, 0].axis('off')\n",
        "\n",
        "#     axs[i, 1].imshow(transformed_img, cmap=\"gray\")\n",
        "#     axs[i, 1].set_title(\"After Histogram Equalization\")\n",
        "#     axs[i, 1].axis('off')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "S9fNZS98jSAB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# def estimate_noise_level(img_path):\n",
        "#     image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
        "#     blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "#     noise = image - blurred\n",
        "#     return np.std(noise)\n",
        "\n",
        "# noise_levels = [estimate_noise_level(img_path) for img_path, _ in data]\n",
        "# mean_noise = np.mean(noise_levels)\n",
        "# std_dev_noise = np.std(noise_levels)\n",
        "\n",
        "\n",
        "# min_noise = np.min(noise_levels)\n",
        "# max_noise = np.max(noise_levels)\n",
        "# normalized_noise_levels = [(x - min_noise) / (max_noise - min_noise) for x in noise_levels]\n",
        "\n",
        "\n",
        "# std_dev_normalized_noise = np.std(normalized_noise_levels)\n",
        "\n",
        "# print(f\"Mean Estimated Noise Level: {mean_noise}\")\n",
        "# print(f\"Standard Deviation of Noise Levels: {std_dev_noise}\")\n",
        "# print(f\"Standard Deviation of Normalized Noise Levels: {std_dev_normalized_noise}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EW3u_bMfv_9",
        "outputId": "28885034-dac0-44ea-d611-8f8e8c62a19a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Estimated Noise Level: 116.96483200309474\n",
            "Standard Deviation of Noise Levels: 6.352618688719487\n",
            "Standard Deviation of Normalized Noise Levels: 0.11683027647538675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Cc3ZQEtyUgpA"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQPz2uOga8GJ",
        "outputId": "7e5add9a-985f-467a-fd2b-5f263433fc80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms.functional as F\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.grayscale_count = 0  # Adding a counter for grayscale images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path, label = self.data[idx]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # we don't really need the following, we changed rare grayscale images to rgb when feeding to the colour_model\n",
        "        # Check and convert grayscale images\n",
        "        # if image.mode != 'RGB':\n",
        "        #     image = image.convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "class HistEqualize(object):\n",
        "    def __call__(self, img):\n",
        "        return F.equalize(img)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '()'\n",
        "\n",
        "#base transform\n",
        "transform_gray = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "])\n",
        "# Gaussian Blur Transformation\n",
        "transform_gaussian = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.GaussianBlur(5),  # Kernel size of 5, you can adjust as needed\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "])\n",
        "\n",
        "# Histogram Equalization Transformation\n",
        "transform_hist_eq = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    HistEqualize(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "])\n",
        "\n",
        "# Data Loaders for the new transformations\n",
        "train_loader_gray = DataLoader(CustomDataset(train_data, transform=transform_gray), batch_size=32, shuffle=True)\n",
        "test_loader_gray = DataLoader(CustomDataset(test_data, transform=transform_gray), batch_size=32)\n",
        "train_loader_gaussian = DataLoader(CustomDataset(train_data, transform=transform_gaussian), batch_size=32, shuffle=True)\n",
        "test_loader_gaussian = DataLoader(CustomDataset(test_data, transform=transform_gaussian), batch_size=32)\n",
        "train_loader_hist_eq = DataLoader(CustomDataset(train_data, transform=transform_hist_eq), batch_size=32, shuffle=True)\n",
        "test_loader_hist_eq = DataLoader(CustomDataset(test_data, transform=transform_hist_eq), batch_size=32)\n",
        "\n",
        "class CustomEfficientNet(nn.Module):\n",
        "    def __init__(self, pretrained_model_name='efficientnet-b0', num_classes=16):\n",
        "        super(CustomEfficientNet, self).__init__()\n",
        "        self.embedding = nn.Conv2d(1, 3, kernel_size=1, stride=1, padding=0)\n",
        "        self.eff_net = EfficientNet.from_pretrained(pretrained_model_name, num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.eff_net(x)\n",
        "        return x\n",
        "model_gray = CustomEfficientNet().to(device)  # For regular grayscale\n",
        "model_gray_gaussian = CustomEfficientNet().to(device)  # For Gaussian-blurred grayscale\n",
        "model_gray_hist_eq = CustomEfficientNet().to(device)  # For histogram-equalized grayscale\n",
        "\n",
        "\n",
        "optimizer_gray = optim.SGD(model_gray.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_gray_gaussian = optim.SGD(model_gray_gaussian.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_gray_hist_eq = optim.SGD(model_gray_hist_eq.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_test_model(model, train_loader, test_loader, optimizer, criterion, epochs_list, model_name):\n",
        "    accuracies = []\n",
        "    cumulative_epochs = 0\n",
        "    for epochs in epochs_list:\n",
        "        cumulative_epochs += epochs\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(train_loader, 0):\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "                if i % 10 == 9:\n",
        "                    print(f'[{cumulative_epochs + epoch + 1}, {i + 1}] loss: {running_loss / 10:.3f}')\n",
        "                    running_loss = 0.0\n",
        "\n",
        "            model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for data in test_loader:\n",
        "                    images, labels = data[0].to(device), data[1].to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "            accuracies.append(accuracy)\n",
        "            print(f'Accuracy of {model_name} after {cumulative_epochs + epoch + 1} epochs on test images: {accuracy:.2f}%')\n",
        "    return accuracies\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AVx_qK9ScsQn",
        "outputId": "0b4881c8-f1ab-4b35-9b2b-a2f46696c59f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 10] loss: 2.779\n",
            "[11, 20] loss: 2.740\n",
            "Accuracy of Gaussian Model after 11 epochs on test images: 8.33%\n",
            "[12, 10] loss: 2.681\n",
            "[12, 20] loss: 2.642\n",
            "Accuracy of Gaussian Model after 12 epochs on test images: 11.98%\n",
            "[13, 10] loss: 2.561\n",
            "[13, 20] loss: 2.537\n",
            "Accuracy of Gaussian Model after 13 epochs on test images: 16.15%\n",
            "[14, 10] loss: 2.468\n",
            "[14, 20] loss: 2.406\n",
            "Accuracy of Gaussian Model after 14 epochs on test images: 22.92%\n",
            "[15, 10] loss: 2.335\n",
            "[15, 20] loss: 2.302\n",
            "Accuracy of Gaussian Model after 15 epochs on test images: 31.77%\n",
            "[16, 10] loss: 2.205\n",
            "[16, 20] loss: 2.207\n",
            "Accuracy of Gaussian Model after 16 epochs on test images: 35.42%\n",
            "[17, 10] loss: 2.138\n",
            "[17, 20] loss: 2.045\n",
            "Accuracy of Gaussian Model after 17 epochs on test images: 41.67%\n",
            "[18, 10] loss: 1.958\n",
            "[18, 20] loss: 1.974\n",
            "Accuracy of Gaussian Model after 18 epochs on test images: 44.27%\n",
            "[19, 10] loss: 1.875\n",
            "[19, 20] loss: 1.810\n",
            "Accuracy of Gaussian Model after 19 epochs on test images: 50.52%\n",
            "[20, 10] loss: 1.794\n",
            "[20, 20] loss: 1.725\n",
            "Accuracy of Gaussian Model after 20 epochs on test images: 55.21%\n",
            "[31, 10] loss: 1.628\n",
            "[31, 20] loss: 1.640\n",
            "Accuracy of Gaussian Model after 31 epochs on test images: 59.38%\n",
            "[32, 10] loss: 1.541\n",
            "[32, 20] loss: 1.508\n",
            "Accuracy of Gaussian Model after 32 epochs on test images: 57.29%\n",
            "[33, 10] loss: 1.427\n",
            "[33, 20] loss: 1.449\n",
            "Accuracy of Gaussian Model after 33 epochs on test images: 61.46%\n",
            "[34, 10] loss: 1.393\n",
            "[34, 20] loss: 1.345\n",
            "Accuracy of Gaussian Model after 34 epochs on test images: 62.50%\n",
            "[35, 10] loss: 1.276\n",
            "[35, 20] loss: 1.283\n",
            "Accuracy of Gaussian Model after 35 epochs on test images: 64.06%\n",
            "[36, 10] loss: 1.234\n",
            "[36, 20] loss: 1.163\n",
            "Accuracy of Gaussian Model after 36 epochs on test images: 64.06%\n",
            "[37, 10] loss: 1.223\n",
            "[37, 20] loss: 1.053\n",
            "Accuracy of Gaussian Model after 37 epochs on test images: 63.54%\n",
            "[38, 10] loss: 1.062\n",
            "[38, 20] loss: 1.142\n",
            "Accuracy of Gaussian Model after 38 epochs on test images: 64.06%\n",
            "[39, 10] loss: 0.974\n",
            "[39, 20] loss: 1.057\n",
            "Accuracy of Gaussian Model after 39 epochs on test images: 65.62%\n",
            "[40, 10] loss: 1.001\n",
            "[40, 20] loss: 0.988\n",
            "Accuracy of Gaussian Model after 40 epochs on test images: 69.79%\n",
            "[41, 10] loss: 0.955\n",
            "[41, 20] loss: 0.876\n",
            "Accuracy of Gaussian Model after 41 epochs on test images: 67.19%\n",
            "[42, 10] loss: 0.871\n",
            "[42, 20] loss: 0.895\n",
            "Accuracy of Gaussian Model after 42 epochs on test images: 69.27%\n",
            "[43, 10] loss: 0.881\n",
            "[43, 20] loss: 0.808\n",
            "Accuracy of Gaussian Model after 43 epochs on test images: 71.88%\n",
            "[44, 10] loss: 0.790\n",
            "[44, 20] loss: 0.854\n",
            "Accuracy of Gaussian Model after 44 epochs on test images: 69.27%\n",
            "[45, 10] loss: 0.706\n",
            "[45, 20] loss: 0.745\n",
            "Accuracy of Gaussian Model after 45 epochs on test images: 73.44%\n",
            "[46, 10] loss: 0.663\n",
            "[46, 20] loss: 0.773\n",
            "Accuracy of Gaussian Model after 46 epochs on test images: 72.92%\n",
            "[47, 10] loss: 0.705\n",
            "[47, 20] loss: 0.641\n",
            "Accuracy of Gaussian Model after 47 epochs on test images: 72.92%\n",
            "[48, 10] loss: 0.647\n",
            "[48, 20] loss: 0.656\n",
            "Accuracy of Gaussian Model after 48 epochs on test images: 75.52%\n",
            "[49, 10] loss: 0.612\n",
            "[49, 20] loss: 0.677\n",
            "Accuracy of Gaussian Model after 49 epochs on test images: 73.44%\n",
            "[50, 10] loss: 0.591\n",
            "[50, 20] loss: 0.605\n",
            "Accuracy of Gaussian Model after 50 epochs on test images: 73.96%\n",
            "[61, 10] loss: 0.575\n",
            "[61, 20] loss: 0.513\n",
            "Accuracy of Gaussian Model after 61 epochs on test images: 73.96%\n",
            "[62, 10] loss: 0.532\n",
            "[62, 20] loss: 0.575\n",
            "Accuracy of Gaussian Model after 62 epochs on test images: 73.44%\n",
            "[63, 10] loss: 0.538\n",
            "[63, 20] loss: 0.509\n",
            "Accuracy of Gaussian Model after 63 epochs on test images: 76.04%\n",
            "[64, 10] loss: 0.453\n",
            "[64, 20] loss: 0.513\n",
            "Accuracy of Gaussian Model after 64 epochs on test images: 74.48%\n",
            "[65, 10] loss: 0.446\n",
            "[65, 20] loss: 0.481\n",
            "Accuracy of Gaussian Model after 65 epochs on test images: 75.00%\n",
            "[66, 10] loss: 0.496\n",
            "[66, 20] loss: 0.446\n",
            "Accuracy of Gaussian Model after 66 epochs on test images: 75.52%\n",
            "[67, 10] loss: 0.404\n",
            "[67, 20] loss: 0.438\n",
            "Accuracy of Gaussian Model after 67 epochs on test images: 76.56%\n",
            "[68, 10] loss: 0.385\n",
            "[68, 20] loss: 0.384\n",
            "Accuracy of Gaussian Model after 68 epochs on test images: 76.56%\n",
            "[69, 10] loss: 0.392\n",
            "[69, 20] loss: 0.390\n",
            "Accuracy of Gaussian Model after 69 epochs on test images: 76.56%\n",
            "[70, 10] loss: 0.400\n",
            "[70, 20] loss: 0.344\n",
            "Accuracy of Gaussian Model after 70 epochs on test images: 75.52%\n",
            "[71, 10] loss: 0.341\n",
            "[71, 20] loss: 0.349\n",
            "Accuracy of Gaussian Model after 71 epochs on test images: 73.44%\n",
            "[72, 10] loss: 0.327\n",
            "[72, 20] loss: 0.336\n",
            "Accuracy of Gaussian Model after 72 epochs on test images: 73.44%\n",
            "[73, 10] loss: 0.298\n",
            "[73, 20] loss: 0.304\n",
            "Accuracy of Gaussian Model after 73 epochs on test images: 76.56%\n",
            "[74, 10] loss: 0.280\n",
            "[74, 20] loss: 0.316\n",
            "Accuracy of Gaussian Model after 74 epochs on test images: 77.60%\n",
            "[75, 10] loss: 0.288\n",
            "[75, 20] loss: 0.291\n",
            "Accuracy of Gaussian Model after 75 epochs on test images: 76.56%\n",
            "[76, 10] loss: 0.261\n",
            "[76, 20] loss: 0.315\n",
            "Accuracy of Gaussian Model after 76 epochs on test images: 74.48%\n",
            "[77, 10] loss: 0.250\n",
            "[77, 20] loss: 0.292\n",
            "Accuracy of Gaussian Model after 77 epochs on test images: 76.04%\n",
            "[78, 10] loss: 0.239\n",
            "[78, 20] loss: 0.244\n",
            "Accuracy of Gaussian Model after 78 epochs on test images: 75.52%\n",
            "[79, 10] loss: 0.260\n",
            "[79, 20] loss: 0.201\n",
            "Accuracy of Gaussian Model after 79 epochs on test images: 77.08%\n",
            "[80, 10] loss: 0.252\n",
            "[80, 20] loss: 0.208\n",
            "Accuracy of Gaussian Model after 80 epochs on test images: 77.08%\n",
            "[81, 10] loss: 0.224\n",
            "[81, 20] loss: 0.179\n",
            "Accuracy of Gaussian Model after 81 epochs on test images: 75.52%\n",
            "[82, 10] loss: 0.193\n",
            "[82, 20] loss: 0.209\n",
            "Accuracy of Gaussian Model after 82 epochs on test images: 74.48%\n",
            "[83, 10] loss: 0.191\n",
            "[83, 20] loss: 0.206\n",
            "Accuracy of Gaussian Model after 83 epochs on test images: 76.56%\n",
            "[84, 10] loss: 0.190\n",
            "[84, 20] loss: 0.230\n",
            "Accuracy of Gaussian Model after 84 epochs on test images: 76.04%\n",
            "[85, 10] loss: 0.180\n",
            "[85, 20] loss: 0.243\n",
            "Accuracy of Gaussian Model after 85 epochs on test images: 76.04%\n",
            "[86, 10] loss: 0.183\n",
            "[86, 20] loss: 0.180\n",
            "Accuracy of Gaussian Model after 86 epochs on test images: 77.08%\n",
            "[87, 10] loss: 0.189\n",
            "[87, 20] loss: 0.161\n",
            "Accuracy of Gaussian Model after 87 epochs on test images: 78.12%\n",
            "[88, 10] loss: 0.126\n",
            "[88, 20] loss: 0.159\n",
            "Accuracy of Gaussian Model after 88 epochs on test images: 76.04%\n",
            "[89, 10] loss: 0.160\n",
            "[89, 20] loss: 0.151\n",
            "Accuracy of Gaussian Model after 89 epochs on test images: 77.60%\n",
            "[90, 10] loss: 0.152\n",
            "[90, 20] loss: 0.165\n",
            "Accuracy of Gaussian Model after 90 epochs on test images: 77.08%\n",
            "[11, 10] loss: 0.030\n",
            "[11, 20] loss: 0.020\n",
            "Accuracy of Histogram Equalization Model after 11 epochs on test images: 76.56%\n",
            "[12, 10] loss: 0.029\n",
            "[12, 20] loss: 0.031\n",
            "Accuracy of Histogram Equalization Model after 12 epochs on test images: 77.08%\n",
            "[13, 10] loss: 0.029\n",
            "[13, 20] loss: 0.026\n",
            "Accuracy of Histogram Equalization Model after 13 epochs on test images: 77.08%\n",
            "[14, 10] loss: 0.033\n",
            "[14, 20] loss: 0.033\n",
            "Accuracy of Histogram Equalization Model after 14 epochs on test images: 77.60%\n",
            "[15, 10] loss: 0.036\n",
            "[15, 20] loss: 0.035\n",
            "Accuracy of Histogram Equalization Model after 15 epochs on test images: 78.65%\n",
            "[16, 10] loss: 0.027\n",
            "[16, 20] loss: 0.027\n",
            "Accuracy of Histogram Equalization Model after 16 epochs on test images: 78.65%\n",
            "[17, 10] loss: 0.027\n",
            "[17, 20] loss: 0.035\n",
            "Accuracy of Histogram Equalization Model after 17 epochs on test images: 78.12%\n",
            "[18, 10] loss: 0.033\n",
            "[18, 20] loss: 0.027\n",
            "Accuracy of Histogram Equalization Model after 18 epochs on test images: 78.65%\n",
            "[19, 10] loss: 0.031\n",
            "[19, 20] loss: 0.019\n",
            "Accuracy of Histogram Equalization Model after 19 epochs on test images: 78.65%\n",
            "[20, 10] loss: 0.019\n",
            "[20, 20] loss: 0.032\n",
            "Accuracy of Histogram Equalization Model after 20 epochs on test images: 78.65%\n",
            "[31, 10] loss: 0.020\n",
            "[31, 20] loss: 0.028\n",
            "Accuracy of Histogram Equalization Model after 31 epochs on test images: 78.65%\n",
            "[32, 10] loss: 0.037\n",
            "[32, 20] loss: 0.027\n",
            "Accuracy of Histogram Equalization Model after 32 epochs on test images: 79.69%\n",
            "[33, 10] loss: 0.024\n",
            "[33, 20] loss: 0.019\n",
            "Accuracy of Histogram Equalization Model after 33 epochs on test images: 78.65%\n",
            "[34, 10] loss: 0.026\n",
            "[34, 20] loss: 0.024\n",
            "Accuracy of Histogram Equalization Model after 34 epochs on test images: 79.17%\n",
            "[35, 10] loss: 0.019\n",
            "[35, 20] loss: 0.035\n",
            "Accuracy of Histogram Equalization Model after 35 epochs on test images: 78.65%\n",
            "[36, 10] loss: 0.023\n",
            "[36, 20] loss: 0.026\n",
            "Accuracy of Histogram Equalization Model after 36 epochs on test images: 79.17%\n",
            "[37, 10] loss: 0.031\n",
            "[37, 20] loss: 0.023\n",
            "Accuracy of Histogram Equalization Model after 37 epochs on test images: 78.65%\n",
            "[38, 10] loss: 0.035\n",
            "[38, 20] loss: 0.025\n",
            "Accuracy of Histogram Equalization Model after 38 epochs on test images: 79.17%\n",
            "[39, 10] loss: 0.029\n",
            "[39, 20] loss: 0.021\n",
            "Accuracy of Histogram Equalization Model after 39 epochs on test images: 79.17%\n",
            "[40, 10] loss: 0.022\n",
            "[40, 20] loss: 0.028\n",
            "Accuracy of Histogram Equalization Model after 40 epochs on test images: 78.65%\n",
            "[41, 10] loss: 0.019\n",
            "[41, 20] loss: 0.026\n",
            "Accuracy of Histogram Equalization Model after 41 epochs on test images: 78.65%\n",
            "[42, 10] loss: 0.018\n",
            "[42, 20] loss: 0.024\n",
            "Accuracy of Histogram Equalization Model after 42 epochs on test images: 79.17%\n",
            "[43, 10] loss: 0.028\n",
            "[43, 20] loss: 0.025\n",
            "Accuracy of Histogram Equalization Model after 43 epochs on test images: 79.17%\n",
            "[44, 10] loss: 0.023\n",
            "[44, 20] loss: 0.017\n",
            "Accuracy of Histogram Equalization Model after 44 epochs on test images: 79.17%\n",
            "[45, 10] loss: 0.023\n",
            "[45, 20] loss: 0.021\n",
            "Accuracy of Histogram Equalization Model after 45 epochs on test images: 79.17%\n",
            "[46, 10] loss: 0.024\n",
            "[46, 20] loss: 0.017\n",
            "Accuracy of Histogram Equalization Model after 46 epochs on test images: 78.65%\n",
            "[47, 10] loss: 0.025\n",
            "[47, 20] loss: 0.024\n",
            "Accuracy of Histogram Equalization Model after 47 epochs on test images: 78.65%\n",
            "[48, 10] loss: 0.017\n",
            "[48, 20] loss: 0.020\n",
            "Accuracy of Histogram Equalization Model after 48 epochs on test images: 78.65%\n",
            "[49, 10] loss: 0.028\n",
            "[49, 20] loss: 0.024\n",
            "Accuracy of Histogram Equalization Model after 49 epochs on test images: 78.65%\n",
            "[50, 10] loss: 0.020\n",
            "[50, 20] loss: 0.019\n",
            "Accuracy of Histogram Equalization Model after 50 epochs on test images: 78.65%\n",
            "[61, 10] loss: 0.025\n",
            "[61, 20] loss: 0.018\n",
            "Accuracy of Histogram Equalization Model after 61 epochs on test images: 79.17%\n",
            "[62, 10] loss: 0.025\n",
            "[62, 20] loss: 0.028\n",
            "Accuracy of Histogram Equalization Model after 62 epochs on test images: 79.17%\n",
            "[63, 10] loss: 0.015\n",
            "[63, 20] loss: 0.027\n",
            "Accuracy of Histogram Equalization Model after 63 epochs on test images: 79.17%\n",
            "[64, 10] loss: 0.018\n",
            "[64, 20] loss: 0.026\n",
            "Accuracy of Histogram Equalization Model after 64 epochs on test images: 78.12%\n",
            "[65, 10] loss: 0.023\n",
            "[65, 20] loss: 0.018\n",
            "Accuracy of Histogram Equalization Model after 65 epochs on test images: 78.12%\n",
            "[66, 10] loss: 0.017\n",
            "[66, 20] loss: 0.020\n",
            "Accuracy of Histogram Equalization Model after 66 epochs on test images: 78.12%\n",
            "[67, 10] loss: 0.020\n",
            "[67, 20] loss: 0.014\n",
            "Accuracy of Histogram Equalization Model after 67 epochs on test images: 78.12%\n",
            "[68, 10] loss: 0.017\n",
            "[68, 20] loss: 0.023\n",
            "Accuracy of Histogram Equalization Model after 68 epochs on test images: 78.12%\n",
            "[69, 10] loss: 0.023\n",
            "[69, 20] loss: 0.021\n",
            "Accuracy of Histogram Equalization Model after 69 epochs on test images: 78.65%\n",
            "[70, 10] loss: 0.024\n",
            "[70, 20] loss: 0.019\n",
            "Accuracy of Histogram Equalization Model after 70 epochs on test images: 78.65%\n",
            "[71, 10] loss: 0.020\n",
            "[71, 20] loss: 0.020\n",
            "Accuracy of Histogram Equalization Model after 71 epochs on test images: 78.65%\n",
            "[72, 10] loss: 0.017\n",
            "[72, 20] loss: 0.017\n",
            "Accuracy of Histogram Equalization Model after 72 epochs on test images: 78.12%\n",
            "[73, 10] loss: 0.030\n",
            "[73, 20] loss: 0.019\n",
            "Accuracy of Histogram Equalization Model after 73 epochs on test images: 78.12%\n",
            "[74, 10] loss: 0.015\n",
            "[74, 20] loss: 0.018\n",
            "Accuracy of Histogram Equalization Model after 74 epochs on test images: 78.65%\n",
            "[75, 10] loss: 0.024\n",
            "[75, 20] loss: 0.014\n",
            "Accuracy of Histogram Equalization Model after 75 epochs on test images: 79.17%\n",
            "[76, 10] loss: 0.015\n",
            "[76, 20] loss: 0.015\n",
            "Accuracy of Histogram Equalization Model after 76 epochs on test images: 79.17%\n",
            "[77, 10] loss: 0.019\n",
            "[77, 20] loss: 0.018\n",
            "Accuracy of Histogram Equalization Model after 77 epochs on test images: 78.12%\n",
            "[78, 10] loss: 0.016\n",
            "[78, 20] loss: 0.015\n",
            "Accuracy of Histogram Equalization Model after 78 epochs on test images: 78.12%\n",
            "[79, 10] loss: 0.014\n",
            "[79, 20] loss: 0.018\n",
            "Accuracy of Histogram Equalization Model after 79 epochs on test images: 78.65%\n",
            "[80, 10] loss: 0.012\n",
            "[80, 20] loss: 0.015\n",
            "Accuracy of Histogram Equalization Model after 80 epochs on test images: 78.65%\n",
            "[81, 10] loss: 0.011\n",
            "[81, 20] loss: 0.023\n",
            "Accuracy of Histogram Equalization Model after 81 epochs on test images: 78.65%\n",
            "[82, 10] loss: 0.015\n",
            "[82, 20] loss: 0.023\n",
            "Accuracy of Histogram Equalization Model after 82 epochs on test images: 78.65%\n",
            "[83, 10] loss: 0.018\n",
            "[83, 20] loss: 0.017\n",
            "Accuracy of Histogram Equalization Model after 83 epochs on test images: 78.65%\n",
            "[84, 10] loss: 0.019\n",
            "[84, 20] loss: 0.023\n",
            "Accuracy of Histogram Equalization Model after 84 epochs on test images: 78.12%\n",
            "[85, 10] loss: 0.017\n",
            "[85, 20] loss: 0.019\n",
            "Accuracy of Histogram Equalization Model after 85 epochs on test images: 78.65%\n",
            "[86, 10] loss: 0.013\n",
            "[86, 20] loss: 0.019\n",
            "Accuracy of Histogram Equalization Model after 86 epochs on test images: 78.12%\n",
            "[87, 10] loss: 0.013\n",
            "[87, 20] loss: 0.012\n",
            "Accuracy of Histogram Equalization Model after 87 epochs on test images: 78.12%\n",
            "[88, 10] loss: 0.015\n",
            "[88, 20] loss: 0.017\n",
            "Accuracy of Histogram Equalization Model after 88 epochs on test images: 78.65%\n",
            "[89, 10] loss: 0.012\n",
            "[89, 20] loss: 0.019\n",
            "Accuracy of Histogram Equalization Model after 89 epochs on test images: 78.65%\n",
            "[90, 10] loss: 0.016\n",
            "[90, 20] loss: 0.019\n",
            "Accuracy of Histogram Equalization Model after 90 epochs on test images: 78.65%\n",
            "[11, 10] loss: 2.777\n",
            "[11, 20] loss: 2.737\n",
            "Accuracy of Grayscale Model after 11 epochs on test images: 13.54%\n",
            "[12, 10] loss: 2.661\n",
            "[12, 20] loss: 2.604\n",
            "Accuracy of Grayscale Model after 12 epochs on test images: 23.44%\n",
            "[13, 10] loss: 2.513\n",
            "[13, 20] loss: 2.460\n",
            "Accuracy of Grayscale Model after 13 epochs on test images: 33.33%\n",
            "[14, 10] loss: 2.363\n",
            "[14, 20] loss: 2.309\n",
            "Accuracy of Grayscale Model after 14 epochs on test images: 39.58%\n",
            "[15, 10] loss: 2.207\n",
            "[15, 20] loss: 2.184\n",
            "Accuracy of Grayscale Model after 15 epochs on test images: 45.31%\n",
            "[16, 10] loss: 2.098\n",
            "[16, 20] loss: 2.024\n",
            "Accuracy of Grayscale Model after 16 epochs on test images: 49.48%\n",
            "[17, 10] loss: 1.915\n",
            "[17, 20] loss: 1.887\n",
            "Accuracy of Grayscale Model after 17 epochs on test images: 50.00%\n",
            "[18, 10] loss: 1.805\n",
            "[18, 20] loss: 1.721\n",
            "Accuracy of Grayscale Model after 18 epochs on test images: 55.73%\n",
            "[19, 10] loss: 1.698\n",
            "[19, 20] loss: 1.586\n",
            "Accuracy of Grayscale Model after 19 epochs on test images: 58.33%\n",
            "[20, 10] loss: 1.487\n",
            "[20, 20] loss: 1.505\n",
            "Accuracy of Grayscale Model after 20 epochs on test images: 60.94%\n",
            "[31, 10] loss: 1.370\n",
            "[31, 20] loss: 1.393\n",
            "Accuracy of Grayscale Model after 31 epochs on test images: 61.98%\n",
            "[32, 10] loss: 1.319\n",
            "[32, 20] loss: 1.324\n",
            "Accuracy of Grayscale Model after 32 epochs on test images: 64.58%\n",
            "[33, 10] loss: 1.232\n",
            "[33, 20] loss: 1.143\n",
            "Accuracy of Grayscale Model after 33 epochs on test images: 64.58%\n",
            "[34, 10] loss: 1.182\n",
            "[34, 20] loss: 1.085\n",
            "Accuracy of Grayscale Model after 34 epochs on test images: 65.62%\n",
            "[35, 10] loss: 1.058\n",
            "[35, 20] loss: 1.016\n",
            "Accuracy of Grayscale Model after 35 epochs on test images: 66.15%\n",
            "[36, 10] loss: 0.950\n",
            "[36, 20] loss: 0.966\n",
            "Accuracy of Grayscale Model after 36 epochs on test images: 66.67%\n",
            "[37, 10] loss: 0.885\n",
            "[37, 20] loss: 0.885\n",
            "Accuracy of Grayscale Model after 37 epochs on test images: 68.75%\n",
            "[38, 10] loss: 0.814\n",
            "[38, 20] loss: 0.862\n",
            "Accuracy of Grayscale Model after 38 epochs on test images: 70.31%\n",
            "[39, 10] loss: 0.765\n",
            "[39, 20] loss: 0.795\n",
            "Accuracy of Grayscale Model after 39 epochs on test images: 70.83%\n",
            "[40, 10] loss: 0.768\n",
            "[40, 20] loss: 0.729\n",
            "Accuracy of Grayscale Model after 40 epochs on test images: 72.92%\n",
            "[41, 10] loss: 0.660\n",
            "[41, 20] loss: 0.738\n",
            "Accuracy of Grayscale Model after 41 epochs on test images: 73.96%\n",
            "[42, 10] loss: 0.670\n",
            "[42, 20] loss: 0.647\n",
            "Accuracy of Grayscale Model after 42 epochs on test images: 73.96%\n",
            "[43, 10] loss: 0.630\n",
            "[43, 20] loss: 0.603\n",
            "Accuracy of Grayscale Model after 43 epochs on test images: 75.52%\n",
            "[44, 10] loss: 0.557\n",
            "[44, 20] loss: 0.569\n",
            "Accuracy of Grayscale Model after 44 epochs on test images: 74.48%\n",
            "[45, 10] loss: 0.581\n",
            "[45, 20] loss: 0.519\n",
            "Accuracy of Grayscale Model after 45 epochs on test images: 76.04%\n",
            "[46, 10] loss: 0.535\n",
            "[46, 20] loss: 0.474\n",
            "Accuracy of Grayscale Model after 46 epochs on test images: 77.08%\n",
            "[47, 10] loss: 0.491\n",
            "[47, 20] loss: 0.444\n",
            "Accuracy of Grayscale Model after 47 epochs on test images: 77.08%\n",
            "[48, 10] loss: 0.479\n",
            "[48, 20] loss: 0.454\n",
            "Accuracy of Grayscale Model after 48 epochs on test images: 77.60%\n",
            "[49, 10] loss: 0.418\n",
            "[49, 20] loss: 0.427\n",
            "Accuracy of Grayscale Model after 49 epochs on test images: 76.56%\n",
            "[50, 10] loss: 0.369\n",
            "[50, 20] loss: 0.415\n",
            "Accuracy of Grayscale Model after 50 epochs on test images: 77.08%\n",
            "[61, 10] loss: 0.421\n",
            "[61, 20] loss: 0.345\n",
            "Accuracy of Grayscale Model after 61 epochs on test images: 76.56%\n",
            "[62, 10] loss: 0.348\n",
            "[62, 20] loss: 0.378\n",
            "Accuracy of Grayscale Model after 62 epochs on test images: 76.56%\n",
            "[63, 10] loss: 0.342\n",
            "[63, 20] loss: 0.332\n",
            "Accuracy of Grayscale Model after 63 epochs on test images: 77.08%\n",
            "[64, 10] loss: 0.333\n",
            "[64, 20] loss: 0.342\n",
            "Accuracy of Grayscale Model after 64 epochs on test images: 76.56%\n",
            "[65, 10] loss: 0.321\n",
            "[65, 20] loss: 0.296\n",
            "Accuracy of Grayscale Model after 65 epochs on test images: 76.56%\n",
            "[66, 10] loss: 0.276\n",
            "[66, 20] loss: 0.310\n",
            "Accuracy of Grayscale Model after 66 epochs on test images: 77.60%\n",
            "[67, 10] loss: 0.284\n",
            "[67, 20] loss: 0.256\n",
            "Accuracy of Grayscale Model after 67 epochs on test images: 78.12%\n",
            "[68, 10] loss: 0.286\n",
            "[68, 20] loss: 0.280\n",
            "Accuracy of Grayscale Model after 68 epochs on test images: 78.12%\n",
            "[69, 10] loss: 0.260\n",
            "[69, 20] loss: 0.254\n",
            "Accuracy of Grayscale Model after 69 epochs on test images: 78.12%\n",
            "[70, 10] loss: 0.230\n",
            "[70, 20] loss: 0.232\n",
            "Accuracy of Grayscale Model after 70 epochs on test images: 78.12%\n",
            "[71, 10] loss: 0.207\n",
            "[71, 20] loss: 0.194\n",
            "Accuracy of Grayscale Model after 71 epochs on test images: 79.17%\n",
            "[72, 10] loss: 0.234\n",
            "[72, 20] loss: 0.197\n",
            "Accuracy of Grayscale Model after 72 epochs on test images: 78.12%\n",
            "[73, 10] loss: 0.202\n",
            "[73, 20] loss: 0.186\n",
            "Accuracy of Grayscale Model after 73 epochs on test images: 78.12%\n",
            "[74, 10] loss: 0.191\n",
            "[74, 20] loss: 0.194\n",
            "Accuracy of Grayscale Model after 74 epochs on test images: 78.12%\n",
            "[75, 10] loss: 0.193\n",
            "[75, 20] loss: 0.206\n",
            "Accuracy of Grayscale Model after 75 epochs on test images: 78.12%\n",
            "[76, 10] loss: 0.165\n",
            "[76, 20] loss: 0.162\n",
            "Accuracy of Grayscale Model after 76 epochs on test images: 78.65%\n",
            "[77, 10] loss: 0.155\n",
            "[77, 20] loss: 0.168\n",
            "Accuracy of Grayscale Model after 77 epochs on test images: 78.65%\n",
            "[78, 10] loss: 0.170\n",
            "[78, 20] loss: 0.133\n",
            "Accuracy of Grayscale Model after 78 epochs on test images: 78.65%\n",
            "[79, 10] loss: 0.139\n",
            "[79, 20] loss: 0.163\n",
            "Accuracy of Grayscale Model after 79 epochs on test images: 78.65%\n",
            "[80, 10] loss: 0.139\n",
            "[80, 20] loss: 0.137\n",
            "Accuracy of Grayscale Model after 80 epochs on test images: 78.65%\n",
            "[81, 10] loss: 0.139\n",
            "[81, 20] loss: 0.135\n",
            "Accuracy of Grayscale Model after 81 epochs on test images: 80.21%\n",
            "[82, 10] loss: 0.133\n",
            "[82, 20] loss: 0.116\n",
            "Accuracy of Grayscale Model after 82 epochs on test images: 80.21%\n",
            "[83, 10] loss: 0.126\n",
            "[83, 20] loss: 0.109\n",
            "Accuracy of Grayscale Model after 83 epochs on test images: 79.69%\n",
            "[84, 10] loss: 0.126\n",
            "[84, 20] loss: 0.095\n",
            "Accuracy of Grayscale Model after 84 epochs on test images: 80.21%\n",
            "[85, 10] loss: 0.124\n",
            "[85, 20] loss: 0.116\n",
            "Accuracy of Grayscale Model after 85 epochs on test images: 80.21%\n",
            "[86, 10] loss: 0.138\n",
            "[86, 20] loss: 0.123\n",
            "Accuracy of Grayscale Model after 86 epochs on test images: 79.69%\n",
            "[87, 10] loss: 0.118\n",
            "[87, 20] loss: 0.103\n",
            "Accuracy of Grayscale Model after 87 epochs on test images: 79.69%\n",
            "[88, 10] loss: 0.115\n",
            "[88, 20] loss: 0.105\n",
            "Accuracy of Grayscale Model after 88 epochs on test images: 79.69%\n",
            "[89, 10] loss: 0.090\n",
            "[89, 20] loss: 0.102\n",
            "Accuracy of Grayscale Model after 89 epochs on test images: 79.69%\n",
            "[90, 10] loss: 0.104\n",
            "[90, 20] loss: 0.075\n",
            "Accuracy of Grayscale Model after 90 epochs on test images: 79.17%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-364ea3415bc0>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m df = pd.DataFrame({\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m'Grayscale_Model_Accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccuracies_gray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ],
      "source": [
        "epochs_list = [10, 20,30,40]\n",
        "# Training and geting accuracies\n",
        "\n",
        "train_loader_gray = DataLoader(CustomDataset(train_data, transform=transform_gray), batch_size=32, shuffle=True)\n",
        "test_loader_gray = DataLoader(CustomDataset(test_data, transform=transform_gray), batch_size=32)\n",
        "train_loader_gaussian = DataLoader(CustomDataset(train_data, transform=transform_gaussian), batch_size=32, shuffle=True)\n",
        "test_loader_gaussian = DataLoader(CustomDataset(test_data, transform=transform_gaussian), batch_size=32)\n",
        "train_loader_hist_eq = DataLoader(CustomDataset(train_data, transform=transform_hist_eq), batch_size=32, shuffle=True)\n",
        "test_loader_hist_eq = DataLoader(CustomDataset(test_data, transform=transform_hist_eq), batch_size=32)\n",
        "\n",
        "# accuracies_hist_eq = train_test_model(model_gray_hist_eq, train_loader_hist_eq, test_loader_hist_eq, optimizer_gray, criterion, epochs_list, \"Histogram Equalization Model\")\n",
        "# accuracies_gaussian = train_test_model(model_gray_gaussian, train_loader_gaussian, test_loader_gaussian, optimizer_gray, criterion, epochs_list, \"Gaussian Model\")\n",
        "\n",
        "\n",
        "\n",
        "accuracies_gaussian = train_test_model(model_gray_gaussian, train_loader_gaussian, test_loader_gaussian, optimizer_gray_gaussian, criterion, epochs_list, \"Gaussian Model\")\n",
        "accuracies_hist_eq = train_test_model(model_gray_hist_eq, train_loader_hist_eq, test_loader_hist_eq, optimizer_gray_hist_eq, criterion, epochs_list, \"Histogram Equalization Model\")\n",
        "accuracies_gray = train_test_model(model_gray, train_loader_gray, test_loader_gray, optimizer_gray, criterion, epochs_list, \"Grayscale Model\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Epochs': [sum(epochs_list[:i+1]) for i in range(len(epochs_list))],\n",
        "    'Grayscale_Model_Accuracy': accuracies_gray,\n",
        "    'Gaussian_Model_Accuracy': accuracies_gaussian,\n",
        "    'Histogram_Model_Accuracy': accuracies_hist_eq,\n",
        "})\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax =plt.subplots(figsize=(12,4))\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "the_table = ax.table(cellText=df.values,colLabels=df.columns,loc='center')\n",
        "the_table.auto_set_font_size(False)\n",
        "the_table.set_fontsize(10)\n",
        "plt.savefig(\"/content/drive/MyDrive/model_accuracies.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(accuracies_gray))\n",
        "print(max(accuracies_gaussian))\n",
        "print(max(accuracies_hist_eq))\n"
      ],
      "metadata": {
        "id": "JaM5df5mJgFE",
        "outputId": "638267d7-b798-4457-9196-3846053dfbf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80.20833333333333\n",
            "78.125\n",
            "79.6875\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLT5pQ85MD3IOP2GRPO4Cc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}